{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a940a427-c4af-41f0-89ee-3641ad65c59f",
   "metadata": {},
   "source": [
    "## Download do Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "12672d9e-9734-4690-a454-7538a21bc6c3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-25T20:41:03.665116Z",
     "iopub.status.busy": "2025-04-25T20:41:03.664715Z",
     "iopub.status.idle": "2025-04-25T20:42:26.499694Z",
     "shell.execute_reply": "2025-04-25T20:42:26.498746Z",
     "shell.execute_reply.started": "2025-04-25T20:41:03.665077Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: kagglehub in /usr/local/lib/python3.11/dist-packages (0.3.12)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from kagglehub) (23.2)\n",
      "Requirement already satisfied: pyyaml in /usr/lib/python3/dist-packages (from kagglehub) (5.4.1)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from kagglehub) (2.31.0)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from kagglehub) (4.66.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->kagglehub) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/lib/python3/dist-packages (from requests->kagglehub) (3.3)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->kagglehub) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/lib/python3/dist-packages (from requests->kagglehub) (2020.6.20)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mDownloading from https://www.kaggle.com/api/v1/datasets/download/lucasmoraes001/orange-train-test?dataset_version_number=1...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5.69G/5.69G [00:41<00:00, 148MB/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting files...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path to dataset files: /root/.cache/kagglehub/datasets/lucasmoraes001/orange-train-test/versions/1\n"
     ]
    }
   ],
   "source": [
    "!pip install kagglehub\n",
    "\n",
    "\n",
    "import kagglehub\n",
    "\n",
    "# Download latest version\n",
    "path = kagglehub.dataset_download(\"lucasmoraes001/orange-train-test\")\n",
    "\n",
    "print(\"Path to dataset files:\", path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b0e4651-cca8-4a70-9b36-bd9c6563cc1b",
   "metadata": {},
   "source": [
    "## Importando dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f775e854-1228-4198-acd1-ee568d329666",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-26T20:14:36.251123Z",
     "iopub.status.busy": "2025-04-26T20:14:36.250229Z",
     "iopub.status.idle": "2025-04-26T20:14:36.255563Z",
     "shell.execute_reply": "2025-04-26T20:14:36.255108Z",
     "shell.execute_reply.started": "2025-04-26T20:14:36.251095Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2 \n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torchvision import transforms\n",
    "from torchvision import models\n",
    "from torchvision.io import decode_image\n",
    "from torchvision.models import resnet50, ResNet50_Weights\n",
    "from PIL import Image\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import TensorDataset\n",
    "from multiprocessing import Pool\n",
    "import os\n",
    "import shutil\n",
    "import mlflow\n",
    "from torcheval.metrics import MulticlassF1Score, MulticlassPrecision, MulticlassRecall, MulticlassConfusionMatrix\n",
    "import mlflow.pytorch\n",
    "from mlflow import MlflowClient\n",
    "\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "\n",
    "def cv2_imshow(img, show=True):\n",
    "    if img is None:\n",
    "        raise FileNotFoundError(\"Imagem não encontrada\")\n",
    "\n",
    "    #img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    if show:\n",
    "        # Exibe a imagem diretamente com OpenCV\n",
    "        cv2.imshow('Imagem lida com cv2', img)\n",
    "        cv2.waitKey(0)  # Espera até pressionar qualquer tecla\n",
    "        cv2.destroyAllWindows()  # Fecha a janela depois\n",
    "    \n",
    "    return img\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2fb3e1dd-9548-43bd-8fe7-70119b47763e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-26T20:14:03.143290Z",
     "iopub.status.busy": "2025-04-26T20:14:03.142822Z",
     "iopub.status.idle": "2025-04-26T20:14:03.461061Z",
     "shell.execute_reply": "2025-04-26T20:14:03.460582Z",
     "shell.execute_reply.started": "2025-04-26T20:14:03.143272Z"
    }
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "Imagem não encontrada",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Verificando tamanho das imagens\u001b[39;00m\n\u001b[32m      3\u001b[39m tamanho = cv2.imread(\u001b[33mr\u001b[39m\u001b[33m'\u001b[39m\u001b[33mC:\u001b[39m\u001b[33m\\\u001b[39m\u001b[33mUsers\u001b[39m\u001b[33m\\\u001b[39m\u001b[33mLucas\u001b[39m\u001b[33m\\\u001b[39m\u001b[33mDocuments\u001b[39m\u001b[33m\\\u001b[39m\u001b[33mGitHub\u001b[39m\u001b[33m\\\u001b[39m\u001b[33mComputer_Vision_ML\u001b[39m\u001b[33m\\\u001b[39m\u001b[33mcomputer_vision\u001b[39m\u001b[33m\\\u001b[39m\u001b[33mdata\u001b[39m\u001b[33m\\\u001b[39m\u001b[33mprocessed\u001b[39m\u001b[33m\\\u001b[39m\u001b[33mtrain\u001b[39m\u001b[33m\\\u001b[39m\u001b[33mcitrus canker\u001b[39m\u001b[33m\\\u001b[39m\u001b[33mc (1).jpg\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m \u001b[43mcv2_imshow\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtamanho\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 29\u001b[39m, in \u001b[36mcv2_imshow\u001b[39m\u001b[34m(img, show)\u001b[39m\n\u001b[32m     27\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcv2_imshow\u001b[39m(img, show=\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[32m     28\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m img \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m29\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mImagem não encontrada\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     31\u001b[39m     \u001b[38;5;66;03m#img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\u001b[39;00m\n\u001b[32m     33\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m show:\n\u001b[32m     34\u001b[39m         \u001b[38;5;66;03m# Exibe a imagem diretamente com OpenCV\u001b[39;00m\n",
      "\u001b[31mFileNotFoundError\u001b[39m: Imagem não encontrada"
     ]
    }
   ],
   "source": [
    "# Verificando tamanho das imagens\n",
    "\n",
    "tamanho = cv2.imread(r'C:\\Users\\Lucas\\Documents\\GitHub\\Computer_Vision_ML\\computer_vision\\data\\processed\\train\\citrus canker\\c (1).jpg')\n",
    "\n",
    "cv2_imshow(tamanho)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0931eab",
   "metadata": {},
   "source": [
    "## Tratando"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0310e620",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funções \n",
    "\n",
    "def salvar_dados(tensores_imagens, classes, nome_arquivo):\n",
    "    # Salva tanto os tensores de imagem quanto as classes em um único arquivo\n",
    "    torch.save({\n",
    "        'imagens': tensores_imagens,\n",
    "        'classes': classes\n",
    "    }, nome_arquivo)\n",
    "    print(f'Dados salvos com sucesso em {nome_arquivo}')\n",
    "\n",
    "def descobrir_classe(path):\n",
    "    nome = os.path.basename(os.path.dirname(path)).lower()\n",
    "    if 'canker' in nome:\n",
    "        return 'citrus_canker'\n",
    "    elif 'healthy' in nome:\n",
    "        return 'healthy'\n",
    "    elif 'melanose' in nome:\n",
    "        return 'melanose'\n",
    "    else:\n",
    "        return 'unknown'\n",
    "\n",
    "def copiar_arquivos(lista_paths, destino_base):\n",
    "    for path in lista_paths:\n",
    "        classe = descobrir_classe(path)\n",
    "        destino_classe = os.path.join(destino_base, classe)\n",
    "        os.makedirs(destino_classe, exist_ok=True)\n",
    "\n",
    "        filename = os.path.basename(path)\n",
    "        dest_path = os.path.join(destino_classe, filename)\n",
    "        shutil.copy(path, dest_path)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "49df687b",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = r'C:\\Users\\Lucas\\Documents\\GitHub\\Computer_Vision_ML\\computer_vision\\data\\raw'\n",
    "\n",
    "caminhos = os.listdir(path)\n",
    "citrus_canker = [os.path.abspath(os.path.join(path, caminhos[1], file)) for file in os.listdir(os.path.join(path, caminhos[1]))]\n",
    "healthy = [os.path.abspath(os.path.join(path, caminhos[2], file)) for file in os.listdir(os.path.join(path, caminhos[2]))]\n",
    "melanose = [os.path.abspath(os.path.join(path, caminhos[3], file)) for file in os.listdir(os.path.join(path, caminhos[3]))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07044c9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Criando amostras\n"
     ]
    }
   ],
   "source": [
    "# Criando amostras\n",
    "print('\\nCriando amostras')\n",
    "amostras_0 = citrus_canker[:100] + healthy[:100] + melanose[:100]\n",
    "classe_amostra = []\n",
    "\n",
    "classe_amostra = classe_treatment(amostras_0)\n",
    "\n",
    "# Processando amostras com Torchvision\n",
    "amostras_0 = img_processing(amostras_0, device)\n",
    "\n",
    "# Aplicando torch.stack nas amostras também\n",
    "amostras_0 = torch.stack(amostras_0)\n",
    "\n",
    "print('\\nAmostras criadas!')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f864ab0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iniciando tratamentos dos dados e a separação da mostra...\n",
      "\n",
      "Classes desequilibradas:\n",
      "\n",
      "Número de Citrus Canker: 3000\n",
      "Número de Healthy: 3000\n",
      "Número de Melanose: 2600\n",
      "\n",
      "Classes atualizadas:\n",
      "\n",
      "Número de Citrus Canker: 2600\n",
      "Número de Healthy: 2600\n",
      "Número de Melanose: 2600\n",
      "\n",
      "Copiando arquivos de treino...\n",
      "Copiando arquivos de teste...\n",
      "Copiando arquivos de avaliação...\n",
      "\n",
      "Arquivos copiados com sucesso!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "import torch\n",
    "\n",
    "print('Iniciando tratamentos dos dados e a separação da mostra...\\n')\n",
    "\n",
    "if len(citrus_canker) != len(healthy) or len(citrus_canker) != len(melanose):\n",
    "    print('Classes desequilibradas:\\n')\n",
    "    print(f'Número de Citrus Canker: {len(citrus_canker)}')\n",
    "    print(f'Número de Healthy: {len(healthy)}')\n",
    "    print(f'Número de Melanose: {len(melanose)}')\n",
    "\n",
    "    # Balanceando as classes\n",
    "    min_len = min(len(citrus_canker), len(healthy), len(melanose))\n",
    "    citrus_canker = citrus_canker[:min_len]\n",
    "    healthy = healthy[:min_len]\n",
    "    melanose = melanose[:min_len]\n",
    "\n",
    "    print('\\nClasses atualizadas:\\n')\n",
    "    print(f'Número de Citrus Canker: {len(citrus_canker)}')\n",
    "    print(f'Número de Healthy: {len(healthy)}')\n",
    "    print(f'Número de Melanose: {len(melanose)}')\n",
    "\n",
    "    # Separando Treino, Teste e Avaliação\n",
    "    train = citrus_canker[:2000] + healthy[:2000] + melanose[:2000]\n",
    "    test = citrus_canker[2000:2300] + healthy[2000:2300] + melanose[2000:2300]\n",
    "    eval = citrus_canker[2300:2600] + healthy[2300:2600] + melanose[2300:2600]\n",
    "\n",
    "    # Define o diretório base onde vai salvar\n",
    "    base_dir = r'C:\\Users\\Lucas\\Documents\\GitHub\\Computer_Vision_ML\\computer_vision\\data\\processed'\n",
    "\n",
    "    # Define as pastas de destino\n",
    "    dirs = {\n",
    "        'train': os.path.join(base_dir, 'train'),\n",
    "        'test': os.path.join(base_dir, 'test'),\n",
    "        'eval': os.path.join(base_dir, 'eval')\n",
    "    }\n",
    "\n",
    "    # Cria as pastas principais se não existirem\n",
    "    for pasta in dirs.values():\n",
    "        os.makedirs(pasta, exist_ok=True)\n",
    "\n",
    "    # Copiando os arquivos\n",
    "    print('\\nCopiando arquivos de treino...')\n",
    "    copiar_arquivos(train, dirs['train'])\n",
    "\n",
    "    print('Copiando arquivos de teste...')\n",
    "    copiar_arquivos(test, dirs['test'])\n",
    "\n",
    "    print('Copiando arquivos de avaliação...')\n",
    "    copiar_arquivos(eval, dirs['eval'])\n",
    "\n",
    "    print('\\nArquivos copiados com sucesso!')\n",
    "\n",
    "else:\n",
    "    print('Classes estão equilibradas ok')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "242d5533",
   "metadata": {},
   "source": [
    "### Criando Dataloaders para dados de treino"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0702a6fc-55c4-4ab1-b2ff-61dddcdbae23",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-26T20:14:07.274309Z",
     "iopub.status.busy": "2025-04-26T20:14:07.273635Z",
     "iopub.status.idle": "2025-04-26T20:14:07.400695Z",
     "shell.execute_reply": "2025-04-26T20:14:07.400304Z",
     "shell.execute_reply.started": "2025-04-26T20:14:07.274279Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    #v2.Grayscale(num_output_channels=1), Resnet espera 3 canais\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "dataset_test = ImageFolder(root=r'C:\\Users\\Lucas\\Documents\\GitHub\\OrangeDetect\\data\\processed\\test', transform=transform) # Automaticamente classifica como 0, 1 e 2 respectivamente a ordem da pasta\n",
    "dataset_train = ImageFolder(root=r'C:\\Users\\Lucas\\Documents\\GitHub\\OrangeDetect\\data\\processed\\train', transform=transform)\n",
    "dataset_eval = ImageFolder(root=r'C:\\Users\\Lucas\\Documents\\GitHub\\OrangeDetect\\data\\processed\\eval', transform=transform)\n",
    "\n",
    "\n",
    "\n",
    "train_dataloader = DataLoader(dataset_train, batch_size=32, num_workers=4,shuffle=True)\n",
    "test_dataloader = DataLoader(dataset_test, batch_size=32, num_workers=4,shuffle=True)\n",
    "eval_dataloader = DataLoader(dataset_eval, batch_size=32, num_workers=4,shuffle=True)\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4c060652",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset ImageFolder\n",
       "    Number of datapoints: 6000\n",
       "    Root location: C:\\Users\\Lucas\\Documents\\GitHub\\OrangeDetect\\data\\processed\\train\n",
       "    StandardTransform\n",
       "Transform: Compose(\n",
       "               Resize(size=(224, 224), interpolation=bilinear, max_size=None, antialias=True)\n",
       "               ToTensor()\n",
       "           )"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70dd8439-e552-4e35-9ed1-55566dcbe566",
   "metadata": {},
   "source": [
    "## Feature Extractor com Resnet50\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9892df68-e8c1-492d-a27c-ea72c70c5b65",
   "metadata": {},
   "source": [
    "### Entendendo Resnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cc5a8fc9-1979-42b2-8a9e-fb09d038256c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-26T20:14:11.137225Z",
     "iopub.status.busy": "2025-04-26T20:14:11.136421Z",
     "iopub.status.idle": "2025-04-26T20:14:11.380478Z",
     "shell.execute_reply": "2025-04-26T20:14:11.379863Z",
     "shell.execute_reply.started": "2025-04-26T20:14:11.137179Z"
    }
   },
   "outputs": [],
   "source": [
    "weights = ResNet50_Weights.DEFAULT\n",
    "\n",
    "model = resnet50(weights=weights).to(device='cuda')  # não esquece de inicializar o modelresnet50\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b0d16301-b205-4b93-93cc-11fab4c9d3fa",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-26T19:30:18.563923Z",
     "iopub.status.busy": "2025-04-26T19:30:18.563923Z",
     "iopub.status.idle": "2025-04-26T19:30:23.017924Z",
     "shell.execute_reply": "2025-04-26T19:30:23.017130Z",
     "shell.execute_reply.started": "2025-04-26T19:30:18.563923Z"
    }
   },
   "outputs": [],
   "source": [
    "for img, label in train_dataloader:\n",
    "    img = img.to(device='cuda')\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "339d06c8-7d98-4648-93f1-fadb63534c59",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-26T19:30:24.800655Z",
     "iopub.status.busy": "2025-04-26T19:30:24.799856Z",
     "iopub.status.idle": "2025-04-26T19:30:24.807733Z",
     "shell.execute_reply": "2025-04-26T19:30:24.806947Z",
     "shell.execute_reply.started": "2025-04-26T19:30:24.800655Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 3, 224, 224])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img.shape # O batch de 32 imagens 224x224 com 1 canal apenas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "53438676-b197-4ad9-ae98-f29453b588c6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-26T19:33:45.459108Z",
     "iopub.status.busy": "2025-04-26T19:33:45.458708Z",
     "iopub.status.idle": "2025-04-26T19:33:46.266934Z",
     "shell.execute_reply": "2025-04-26T19:33:46.265477Z",
     "shell.execute_reply.started": "2025-04-26T19:33:45.459083Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'img' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[17]\u001b[39m\u001b[32m, line 12\u001b[39m\n\u001b[32m      9\u001b[39m preprocess = weights.transforms()\n\u001b[32m     11\u001b[39m \u001b[38;5;66;03m# Step 3: Apply inference preprocessing transforms\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m12\u001b[39m batch = preprocess(\u001b[43mimg\u001b[49m[\u001b[32m0\u001b[39m]).unsqueeze(\u001b[32m0\u001b[39m)\n\u001b[32m     14\u001b[39m \u001b[38;5;66;03m# Step 4: Use the model and print the predicted category\u001b[39;00m\n\u001b[32m     15\u001b[39m prediction = model(batch).squeeze(\u001b[32m0\u001b[39m).softmax(\u001b[32m0\u001b[39m)\n",
      "\u001b[31mNameError\u001b[39m: name 'img' is not defined"
     ]
    }
   ],
   "source": [
    "from torchvision.io import decode_image\n",
    "from torchvision.models import resnet50, ResNet50_Weights\n",
    "\n",
    "\n",
    "# Step 1: Initialize model with the best available weights\n",
    "model.eval()\n",
    "\n",
    "# Step 2: Initialize the inference transforms\n",
    "preprocess = weights.transforms()\n",
    "\n",
    "# Step 3: Apply inference preprocessing transforms\n",
    "batch = preprocess(img[0]).unsqueeze(0)\n",
    "\n",
    "# Step 4: Use the model and print the predicted category\n",
    "prediction = model(batch).squeeze(0).softmax(0)\n",
    "class_id = prediction.argmax().item()\n",
    "score = prediction[class_id].item()\n",
    "category_name = weights.meta[\"categories\"][class_id]\n",
    "print(f\"{category_name}: {100 * score:.1f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0287ba90-406b-45f7-aad7-5ea812868efe",
   "metadata": {},
   "source": [
    "## Começando\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ee7d967",
   "metadata": {},
   "source": [
    "### Testando "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3a2e41ef-6747-44b4-9dc0-560d565f5c48",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-26T20:27:56.837873Z",
     "iopub.status.busy": "2025-04-26T20:27:56.837629Z",
     "iopub.status.idle": "2025-04-26T20:27:57.167461Z",
     "shell.execute_reply": "2025-04-26T20:27:57.165791Z",
     "shell.execute_reply.started": "2025-04-26T20:27:56.837855Z"
    }
   },
   "outputs": [],
   "source": [
    "weights = ResNet50_Weights.DEFAULT\n",
    "\n",
    "model = resnet50(weights=weights).to(device)\n",
    "\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# Parameters of newly constructed modules have requires_grad=True by default\n",
    "num_ftrs = model.fc.in_features\n",
    "model.fc = nn.Linear(num_ftrs, 3)\n",
    "\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Observe that only parameters of final layer are being optimized\n",
    "optimizer_conv = optim.SGD(model.fc.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "# Decay LR by a factor of 0.1 every 7 epochs\n",
    "exp_lr_scheduler = lr_scheduler.StepLR(optimizer_conv, step_size=7, gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "fb4ca4f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (4): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (5): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Linear(in_features=2048, out_features=3, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5f05c171",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1         [-1, 64, 112, 112]           9,408\n",
      "       BatchNorm2d-2         [-1, 64, 112, 112]             128\n",
      "              ReLU-3         [-1, 64, 112, 112]               0\n",
      "         MaxPool2d-4           [-1, 64, 56, 56]               0\n",
      "            Conv2d-5           [-1, 64, 56, 56]           4,096\n",
      "       BatchNorm2d-6           [-1, 64, 56, 56]             128\n",
      "              ReLU-7           [-1, 64, 56, 56]               0\n",
      "            Conv2d-8           [-1, 64, 56, 56]          36,864\n",
      "       BatchNorm2d-9           [-1, 64, 56, 56]             128\n",
      "             ReLU-10           [-1, 64, 56, 56]               0\n",
      "           Conv2d-11          [-1, 256, 56, 56]          16,384\n",
      "      BatchNorm2d-12          [-1, 256, 56, 56]             512\n",
      "           Conv2d-13          [-1, 256, 56, 56]          16,384\n",
      "      BatchNorm2d-14          [-1, 256, 56, 56]             512\n",
      "             ReLU-15          [-1, 256, 56, 56]               0\n",
      "       Bottleneck-16          [-1, 256, 56, 56]               0\n",
      "           Conv2d-17           [-1, 64, 56, 56]          16,384\n",
      "      BatchNorm2d-18           [-1, 64, 56, 56]             128\n",
      "             ReLU-19           [-1, 64, 56, 56]               0\n",
      "           Conv2d-20           [-1, 64, 56, 56]          36,864\n",
      "      BatchNorm2d-21           [-1, 64, 56, 56]             128\n",
      "             ReLU-22           [-1, 64, 56, 56]               0\n",
      "           Conv2d-23          [-1, 256, 56, 56]          16,384\n",
      "      BatchNorm2d-24          [-1, 256, 56, 56]             512\n",
      "             ReLU-25          [-1, 256, 56, 56]               0\n",
      "       Bottleneck-26          [-1, 256, 56, 56]               0\n",
      "           Conv2d-27           [-1, 64, 56, 56]          16,384\n",
      "      BatchNorm2d-28           [-1, 64, 56, 56]             128\n",
      "             ReLU-29           [-1, 64, 56, 56]               0\n",
      "           Conv2d-30           [-1, 64, 56, 56]          36,864\n",
      "      BatchNorm2d-31           [-1, 64, 56, 56]             128\n",
      "             ReLU-32           [-1, 64, 56, 56]               0\n",
      "           Conv2d-33          [-1, 256, 56, 56]          16,384\n",
      "      BatchNorm2d-34          [-1, 256, 56, 56]             512\n",
      "             ReLU-35          [-1, 256, 56, 56]               0\n",
      "       Bottleneck-36          [-1, 256, 56, 56]               0\n",
      "           Conv2d-37          [-1, 128, 56, 56]          32,768\n",
      "      BatchNorm2d-38          [-1, 128, 56, 56]             256\n",
      "             ReLU-39          [-1, 128, 56, 56]               0\n",
      "           Conv2d-40          [-1, 128, 28, 28]         147,456\n",
      "      BatchNorm2d-41          [-1, 128, 28, 28]             256\n",
      "             ReLU-42          [-1, 128, 28, 28]               0\n",
      "           Conv2d-43          [-1, 512, 28, 28]          65,536\n",
      "      BatchNorm2d-44          [-1, 512, 28, 28]           1,024\n",
      "           Conv2d-45          [-1, 512, 28, 28]         131,072\n",
      "      BatchNorm2d-46          [-1, 512, 28, 28]           1,024\n",
      "             ReLU-47          [-1, 512, 28, 28]               0\n",
      "       Bottleneck-48          [-1, 512, 28, 28]               0\n",
      "           Conv2d-49          [-1, 128, 28, 28]          65,536\n",
      "      BatchNorm2d-50          [-1, 128, 28, 28]             256\n",
      "             ReLU-51          [-1, 128, 28, 28]               0\n",
      "           Conv2d-52          [-1, 128, 28, 28]         147,456\n",
      "      BatchNorm2d-53          [-1, 128, 28, 28]             256\n",
      "             ReLU-54          [-1, 128, 28, 28]               0\n",
      "           Conv2d-55          [-1, 512, 28, 28]          65,536\n",
      "      BatchNorm2d-56          [-1, 512, 28, 28]           1,024\n",
      "             ReLU-57          [-1, 512, 28, 28]               0\n",
      "       Bottleneck-58          [-1, 512, 28, 28]               0\n",
      "           Conv2d-59          [-1, 128, 28, 28]          65,536\n",
      "      BatchNorm2d-60          [-1, 128, 28, 28]             256\n",
      "             ReLU-61          [-1, 128, 28, 28]               0\n",
      "           Conv2d-62          [-1, 128, 28, 28]         147,456\n",
      "      BatchNorm2d-63          [-1, 128, 28, 28]             256\n",
      "             ReLU-64          [-1, 128, 28, 28]               0\n",
      "           Conv2d-65          [-1, 512, 28, 28]          65,536\n",
      "      BatchNorm2d-66          [-1, 512, 28, 28]           1,024\n",
      "             ReLU-67          [-1, 512, 28, 28]               0\n",
      "       Bottleneck-68          [-1, 512, 28, 28]               0\n",
      "           Conv2d-69          [-1, 128, 28, 28]          65,536\n",
      "      BatchNorm2d-70          [-1, 128, 28, 28]             256\n",
      "             ReLU-71          [-1, 128, 28, 28]               0\n",
      "           Conv2d-72          [-1, 128, 28, 28]         147,456\n",
      "      BatchNorm2d-73          [-1, 128, 28, 28]             256\n",
      "             ReLU-74          [-1, 128, 28, 28]               0\n",
      "           Conv2d-75          [-1, 512, 28, 28]          65,536\n",
      "      BatchNorm2d-76          [-1, 512, 28, 28]           1,024\n",
      "             ReLU-77          [-1, 512, 28, 28]               0\n",
      "       Bottleneck-78          [-1, 512, 28, 28]               0\n",
      "           Conv2d-79          [-1, 256, 28, 28]         131,072\n",
      "      BatchNorm2d-80          [-1, 256, 28, 28]             512\n",
      "             ReLU-81          [-1, 256, 28, 28]               0\n",
      "           Conv2d-82          [-1, 256, 14, 14]         589,824\n",
      "      BatchNorm2d-83          [-1, 256, 14, 14]             512\n",
      "             ReLU-84          [-1, 256, 14, 14]               0\n",
      "           Conv2d-85         [-1, 1024, 14, 14]         262,144\n",
      "      BatchNorm2d-86         [-1, 1024, 14, 14]           2,048\n",
      "           Conv2d-87         [-1, 1024, 14, 14]         524,288\n",
      "      BatchNorm2d-88         [-1, 1024, 14, 14]           2,048\n",
      "             ReLU-89         [-1, 1024, 14, 14]               0\n",
      "       Bottleneck-90         [-1, 1024, 14, 14]               0\n",
      "           Conv2d-91          [-1, 256, 14, 14]         262,144\n",
      "      BatchNorm2d-92          [-1, 256, 14, 14]             512\n",
      "             ReLU-93          [-1, 256, 14, 14]               0\n",
      "           Conv2d-94          [-1, 256, 14, 14]         589,824\n",
      "      BatchNorm2d-95          [-1, 256, 14, 14]             512\n",
      "             ReLU-96          [-1, 256, 14, 14]               0\n",
      "           Conv2d-97         [-1, 1024, 14, 14]         262,144\n",
      "      BatchNorm2d-98         [-1, 1024, 14, 14]           2,048\n",
      "             ReLU-99         [-1, 1024, 14, 14]               0\n",
      "      Bottleneck-100         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-101          [-1, 256, 14, 14]         262,144\n",
      "     BatchNorm2d-102          [-1, 256, 14, 14]             512\n",
      "            ReLU-103          [-1, 256, 14, 14]               0\n",
      "          Conv2d-104          [-1, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-105          [-1, 256, 14, 14]             512\n",
      "            ReLU-106          [-1, 256, 14, 14]               0\n",
      "          Conv2d-107         [-1, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-108         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-109         [-1, 1024, 14, 14]               0\n",
      "      Bottleneck-110         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-111          [-1, 256, 14, 14]         262,144\n",
      "     BatchNorm2d-112          [-1, 256, 14, 14]             512\n",
      "            ReLU-113          [-1, 256, 14, 14]               0\n",
      "          Conv2d-114          [-1, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-115          [-1, 256, 14, 14]             512\n",
      "            ReLU-116          [-1, 256, 14, 14]               0\n",
      "          Conv2d-117         [-1, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-118         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-119         [-1, 1024, 14, 14]               0\n",
      "      Bottleneck-120         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-121          [-1, 256, 14, 14]         262,144\n",
      "     BatchNorm2d-122          [-1, 256, 14, 14]             512\n",
      "            ReLU-123          [-1, 256, 14, 14]               0\n",
      "          Conv2d-124          [-1, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-125          [-1, 256, 14, 14]             512\n",
      "            ReLU-126          [-1, 256, 14, 14]               0\n",
      "          Conv2d-127         [-1, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-128         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-129         [-1, 1024, 14, 14]               0\n",
      "      Bottleneck-130         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-131          [-1, 256, 14, 14]         262,144\n",
      "     BatchNorm2d-132          [-1, 256, 14, 14]             512\n",
      "            ReLU-133          [-1, 256, 14, 14]               0\n",
      "          Conv2d-134          [-1, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-135          [-1, 256, 14, 14]             512\n",
      "            ReLU-136          [-1, 256, 14, 14]               0\n",
      "          Conv2d-137         [-1, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-138         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-139         [-1, 1024, 14, 14]               0\n",
      "      Bottleneck-140         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-141          [-1, 512, 14, 14]         524,288\n",
      "     BatchNorm2d-142          [-1, 512, 14, 14]           1,024\n",
      "            ReLU-143          [-1, 512, 14, 14]               0\n",
      "          Conv2d-144            [-1, 512, 7, 7]       2,359,296\n",
      "     BatchNorm2d-145            [-1, 512, 7, 7]           1,024\n",
      "            ReLU-146            [-1, 512, 7, 7]               0\n",
      "          Conv2d-147           [-1, 2048, 7, 7]       1,048,576\n",
      "     BatchNorm2d-148           [-1, 2048, 7, 7]           4,096\n",
      "          Conv2d-149           [-1, 2048, 7, 7]       2,097,152\n",
      "     BatchNorm2d-150           [-1, 2048, 7, 7]           4,096\n",
      "            ReLU-151           [-1, 2048, 7, 7]               0\n",
      "      Bottleneck-152           [-1, 2048, 7, 7]               0\n",
      "          Conv2d-153            [-1, 512, 7, 7]       1,048,576\n",
      "     BatchNorm2d-154            [-1, 512, 7, 7]           1,024\n",
      "            ReLU-155            [-1, 512, 7, 7]               0\n",
      "          Conv2d-156            [-1, 512, 7, 7]       2,359,296\n",
      "     BatchNorm2d-157            [-1, 512, 7, 7]           1,024\n",
      "            ReLU-158            [-1, 512, 7, 7]               0\n",
      "          Conv2d-159           [-1, 2048, 7, 7]       1,048,576\n",
      "     BatchNorm2d-160           [-1, 2048, 7, 7]           4,096\n",
      "            ReLU-161           [-1, 2048, 7, 7]               0\n",
      "      Bottleneck-162           [-1, 2048, 7, 7]               0\n",
      "          Conv2d-163            [-1, 512, 7, 7]       1,048,576\n",
      "     BatchNorm2d-164            [-1, 512, 7, 7]           1,024\n",
      "            ReLU-165            [-1, 512, 7, 7]               0\n",
      "          Conv2d-166            [-1, 512, 7, 7]       2,359,296\n",
      "     BatchNorm2d-167            [-1, 512, 7, 7]           1,024\n",
      "            ReLU-168            [-1, 512, 7, 7]               0\n",
      "          Conv2d-169           [-1, 2048, 7, 7]       1,048,576\n",
      "     BatchNorm2d-170           [-1, 2048, 7, 7]           4,096\n",
      "            ReLU-171           [-1, 2048, 7, 7]               0\n",
      "      Bottleneck-172           [-1, 2048, 7, 7]               0\n",
      "AdaptiveAvgPool2d-173           [-1, 2048, 1, 1]               0\n",
      "          Linear-174                    [-1, 3]           6,147\n",
      "================================================================\n",
      "Total params: 23,514,179\n",
      "Trainable params: 6,147\n",
      "Non-trainable params: 23,508,032\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.57\n",
      "Forward/backward pass size (MB): 286.55\n",
      "Params size (MB): 89.70\n",
      "Estimated Total Size (MB): 376.82\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from torchsummary import summary\n",
    "\n",
    "model.to(device='cuda')\n",
    "summary(model, input_size=(3, 224, 224), device='cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e6aa3778-be74-4f5a-bdc9-76c1d14fb2b5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-26T20:27:59.323385Z",
     "iopub.status.busy": "2025-04-26T20:27:59.323164Z",
     "iopub.status.idle": "2025-04-26T20:50:57.018726Z",
     "shell.execute_reply": "2025-04-26T20:50:57.017973Z",
     "shell.execute_reply.started": "2025-04-26T20:27:59.323363Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------Época 1------\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[25]\u001b[39m\u001b[32m, line 12\u001b[39m\n\u001b[32m     10\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(epochs):\n\u001b[32m     11\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33m------Época \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch+\u001b[32m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m------\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m12\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtest_dataloader\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m     13\u001b[39m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mcuda\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mcuda\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     16\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpred\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Lucas\\anaconda3\\envs\\computer_vision\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:733\u001b[39m, in \u001b[36m_BaseDataLoaderIter.__next__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    730\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    731\u001b[39m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[32m    732\u001b[39m     \u001b[38;5;28mself\u001b[39m._reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m733\u001b[39m data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    734\u001b[39m \u001b[38;5;28mself\u001b[39m._num_yielded += \u001b[32m1\u001b[39m\n\u001b[32m    735\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m    736\u001b[39m     \u001b[38;5;28mself\u001b[39m._dataset_kind == _DatasetKind.Iterable\n\u001b[32m    737\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    738\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._num_yielded > \u001b[38;5;28mself\u001b[39m._IterableDataset_len_called\n\u001b[32m    739\u001b[39m ):\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Lucas\\anaconda3\\envs\\computer_vision\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:1491\u001b[39m, in \u001b[36m_MultiProcessingDataLoaderIter._next_data\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1488\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._process_data(data, worker_id)\n\u001b[32m   1490\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m._shutdown \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._tasks_outstanding > \u001b[32m0\u001b[39m\n\u001b[32m-> \u001b[39m\u001b[32m1491\u001b[39m idx, data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_get_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1492\u001b[39m \u001b[38;5;28mself\u001b[39m._tasks_outstanding -= \u001b[32m1\u001b[39m\n\u001b[32m   1493\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._dataset_kind == _DatasetKind.Iterable:\n\u001b[32m   1494\u001b[39m     \u001b[38;5;66;03m# Check for _IterableDatasetStopIteration\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Lucas\\anaconda3\\envs\\computer_vision\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:1453\u001b[39m, in \u001b[36m_MultiProcessingDataLoaderIter._get_data\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1449\u001b[39m     \u001b[38;5;66;03m# In this case, `self._data_queue` is a `queue.Queue`,. But we don't\u001b[39;00m\n\u001b[32m   1450\u001b[39m     \u001b[38;5;66;03m# need to call `.task_done()` because we don't use `.join()`.\u001b[39;00m\n\u001b[32m   1451\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1452\u001b[39m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1453\u001b[39m         success, data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_try_get_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1454\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m success:\n\u001b[32m   1455\u001b[39m             \u001b[38;5;28;01mreturn\u001b[39;00m data\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Lucas\\anaconda3\\envs\\computer_vision\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:1284\u001b[39m, in \u001b[36m_MultiProcessingDataLoaderIter._try_get_data\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m   1271\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_try_get_data\u001b[39m(\u001b[38;5;28mself\u001b[39m, timeout=_utils.MP_STATUS_CHECK_INTERVAL):\n\u001b[32m   1272\u001b[39m     \u001b[38;5;66;03m# Tries to fetch data from `self._data_queue` once for a given timeout.\u001b[39;00m\n\u001b[32m   1273\u001b[39m     \u001b[38;5;66;03m# This can also be used as inner loop of fetching without timeout, with\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   1281\u001b[39m     \u001b[38;5;66;03m# Returns a 2-tuple:\u001b[39;00m\n\u001b[32m   1282\u001b[39m     \u001b[38;5;66;03m#   (bool: whether successfully get data, any: data if successful else None)\u001b[39;00m\n\u001b[32m   1283\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1284\u001b[39m         data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_data_queue\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1285\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m (\u001b[38;5;28;01mTrue\u001b[39;00m, data)\n\u001b[32m   1286\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m   1287\u001b[39m         \u001b[38;5;66;03m# At timeout and error, we manually check whether any worker has\u001b[39;00m\n\u001b[32m   1288\u001b[39m         \u001b[38;5;66;03m# failed. Note that this is the only mechanism for Windows to detect\u001b[39;00m\n\u001b[32m   1289\u001b[39m         \u001b[38;5;66;03m# worker failures.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Lucas\\anaconda3\\envs\\computer_vision\\Lib\\multiprocessing\\queues.py:113\u001b[39m, in \u001b[36mQueue.get\u001b[39m\u001b[34m(self, block, timeout)\u001b[39m\n\u001b[32m    111\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m block:\n\u001b[32m    112\u001b[39m     timeout = deadline - time.monotonic()\n\u001b[32m--> \u001b[39m\u001b[32m113\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_poll\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[32m    114\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m Empty\n\u001b[32m    115\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m._poll():\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Lucas\\anaconda3\\envs\\computer_vision\\Lib\\multiprocessing\\connection.py:257\u001b[39m, in \u001b[36m_ConnectionBase.poll\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m    255\u001b[39m \u001b[38;5;28mself\u001b[39m._check_closed()\n\u001b[32m    256\u001b[39m \u001b[38;5;28mself\u001b[39m._check_readable()\n\u001b[32m--> \u001b[39m\u001b[32m257\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_poll\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Lucas\\anaconda3\\envs\\computer_vision\\Lib\\multiprocessing\\connection.py:346\u001b[39m, in \u001b[36mPipeConnection._poll\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m    343\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._got_empty_message \u001b[38;5;129;01mor\u001b[39;00m\n\u001b[32m    344\u001b[39m             _winapi.PeekNamedPipe(\u001b[38;5;28mself\u001b[39m._handle)[\u001b[32m0\u001b[39m] != \u001b[32m0\u001b[39m):\n\u001b[32m    345\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m346\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mbool\u001b[39m(\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Lucas\\anaconda3\\envs\\computer_vision\\Lib\\multiprocessing\\connection.py:1084\u001b[39m, in \u001b[36mwait\u001b[39m\u001b[34m(object_list, timeout)\u001b[39m\n\u001b[32m   1081\u001b[39m                 ready_objects.add(o)\n\u001b[32m   1082\u001b[39m                 timeout = \u001b[32m0\u001b[39m\n\u001b[32m-> \u001b[39m\u001b[32m1084\u001b[39m     ready_handles = \u001b[43m_exhaustive_wait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwaithandle_to_obj\u001b[49m\u001b[43m.\u001b[49m\u001b[43mkeys\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1085\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m   1086\u001b[39m     \u001b[38;5;66;03m# request that overlapped reads stop\u001b[39;00m\n\u001b[32m   1087\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m ov \u001b[38;5;129;01min\u001b[39;00m ov_list:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Lucas\\anaconda3\\envs\\computer_vision\\Lib\\multiprocessing\\connection.py:1016\u001b[39m, in \u001b[36m_exhaustive_wait\u001b[39m\u001b[34m(handles, timeout)\u001b[39m\n\u001b[32m   1014\u001b[39m ready = []\n\u001b[32m   1015\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m L:\n\u001b[32m-> \u001b[39m\u001b[32m1016\u001b[39m     res = \u001b[43m_winapi\u001b[49m\u001b[43m.\u001b[49m\u001b[43mWaitForMultipleObjects\u001b[49m\u001b[43m(\u001b[49m\u001b[43mL\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1017\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m res == WAIT_TIMEOUT:\n\u001b[32m   1018\u001b[39m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# Testando\n",
    "\n",
    "# Usando o test_dataloader apenas para testar o código, pois este dataloader tem apenas 300 imagens.\n",
    "\n",
    "model.train()\n",
    "epochs = 3\n",
    "\n",
    "size = len(test_dataloader.dataset)\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    print(f'------Época {epoch+1}------')\n",
    "    for batch, (X, y) in enumerate(test_dataloader):\n",
    "        X, y = X.to(device='cuda'), y.to(device='cuda')\n",
    "    \n",
    "        \n",
    "        pred = model(X)\n",
    "        loss = criterion(pred, y)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer_conv.step()\n",
    "        optimizer_conv.zero_grad()\n",
    "\n",
    "        if batch % 100 == 0:\n",
    "            print(f'Loss Atual: {loss.item()}')\n",
    "\n",
    "    print('Avaliando o modelo')\n",
    "    size_eval = len(eval_dataloader.dataset)\n",
    "    model.eval()\n",
    "    test_loss, correct = 0, 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for X_test, y_test in eval_dataloader:\n",
    "            X_test = X_test.to(device='cuda')\n",
    "            y_test = y_test.to(device='cuda')\n",
    "            pred = model(X_test)\n",
    "            test_loss += criterion(pred, y_test).item()\n",
    "            predicted = (pred > 0.5).float()\n",
    "            predicted = predicted.argmax(dim=1)\n",
    "            correct += (predicted == y_test).sum().item()\n",
    "    accuracy = correct / size_eval\n",
    "    print(f'Acurácia é {accuracy * 100:.2f}%')\n",
    "    model.train()  # Volta pro modo de treino\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "f43afd84",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "test_loss, correct = 0, 0\n",
    "\n",
    "y_pred = []\n",
    "y = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for X_test, y_test in eval_dataloader:\n",
    "        X_test = X_test.to(device='cuda')\n",
    "        y_test = y_test.to(device='cuda')\n",
    "        pred = model(X_test)\n",
    "        test_loss += criterion(pred, y_test).item()\n",
    "        predicted = (pred > 0.5).float()\n",
    "        predicted = predicted.argmax(dim=1)\n",
    "        y_pred.append(predicted)\n",
    "        y.append(y_test)\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "5b86da7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = torch.cat(y_pred, dim=0) \n",
    "y = torch.cat(y, dim=0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66a42a30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.3333, device='cuda:0')"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torcheval.metrics.functional import multiclass_f1_score, multiclass_precision, multiclass_recall\n",
    "input = torch.tensor([0, 2, 1, 3])\n",
    "target = torch.tensor([0, 1, 2, 3])\n",
    "multiclass_f1_score(y_pred, y, num_classes=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dac39e6",
   "metadata": {},
   "source": [
    "### Experimento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2ddaf48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "cdc91a80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importando modelo e seus pesos\n",
    "weights = ResNet50_Weights.DEFAULT\n",
    "\n",
    "model = resnet50(weights=weights)\n",
    "\n",
    "# Congelando as camadas de convolução\n",
    "\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# Ativando apenas as camadas FC (camadas lineares)\n",
    "\n",
    "# Parameters of newly constructed modules have requires_grad=True by default\n",
    "num_ftrs = model.fc.in_features\n",
    "model.fc = nn.Linear(num_ftrs, 3)\n",
    "\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "optimizer_conv = optim.SGD(model.fc.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "exp_lr_scheduler = lr_scheduler.StepLR(optimizer_conv, step_size=7, gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c496e31f-876e-4bb4-b6e0-2dab2c93a6c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/04/28 16:51:02 WARNING mlflow.utils.autologging_utils: MLflow pytorch autologging is known to be compatible with 1.9.0 <= torch <= 2.6.0, but the installed version is 2.7.0+cu128. If you encounter errors during autologging, try upgrading / downgrading torch to a compatible version, or try upgrading MLflow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------Época 1------\n",
      "Loss Atual: 1.0864379405975342\n",
      "Loss Atual: 0.6003836393356323\n",
      "\n",
      "Avaliando o modelo...\n",
      "Acurácia: 91.11%\n",
      "\n",
      "Testando o modelo e logando métricas\n",
      "\n",
      "Métricas logadas\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/04/28 16:55:16 WARNING mlflow.utils.requirements_utils: Found torch version (2.7.0+cu128) contains a local version label (+cu128). MLflow logged a pip requirement for this package as 'torch==2.7.0' without the local version label to make it installable from PyPI. To specify pip requirements containing local version labels, please use `conda_env` or `pip_requirements`.\n",
      "2025/04/28 16:55:30 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    }
   ],
   "source": [
    "# Modelo para GPU\n",
    "\n",
    "model.to(device)\n",
    "\n",
    "\n",
    "# Iniciar um experimento no MLflow\n",
    "\n",
    "mlflow.set_experiment(\"Orange Detect\")\n",
    "\n",
    "mlflow.pytorch.autolog()\n",
    "\n",
    "# Iniciar o run no MLflow\n",
    "with mlflow.start_run() as run:\n",
    "\n",
    "    # Logar hiperparâmetros\n",
    "    params = {\n",
    "        'Loss Function' : criterion,\n",
    "        'Optimizer' : optimizer_conv\n",
    "    }\n",
    "    mlflow.log_params(params)\n",
    "\n",
    "    # Treinamento\n",
    "    model.train()\n",
    "    epochs = 1\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        print(f'------Época {epoch+1}------')\n",
    "        for batch, (X, y) in enumerate(train_dataloader):\n",
    "            X, y = X.to(device), y.to(device)\n",
    "\n",
    "            pred = model(X)\n",
    "            loss = criterion(pred, y)\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer_conv.step()\n",
    "            optimizer_conv.zero_grad()\n",
    "\n",
    "            if batch % 100 == 0:\n",
    "                print(f'Loss Atual: {loss.item()}')\n",
    "\n",
    "        print('\\nAvaliando o modelo...')\n",
    "        model.eval()\n",
    "        correct = 0\n",
    "        total_loss = 0\n",
    "        with torch.no_grad():\n",
    "            for X_test, y_test in eval_dataloader:\n",
    "                X_test, y_test = X_test.to(device), y_test.to(device)\n",
    "                pred = model(X_test)\n",
    "                total_loss += criterion(pred, y_test).item()\n",
    "                predicted = (pred > 0.5).float()\n",
    "                predicted = predicted.argmax(dim=1)\n",
    "                correct += (predicted == y_test).sum().item()\n",
    "\n",
    "        accuracy = correct / len(eval_dataloader.dataset)\n",
    "        print(f'Acurácia: {accuracy * 100:.2f}%')\n",
    "\n",
    "    # Testando modelo \n",
    "\n",
    "    print('\\nTestando o modelo e logando métricas')\n",
    "    model.eval()\n",
    "    y_correct = []\n",
    "    y_pred = []\n",
    "    with torch.no_grad():\n",
    "        for X, y in test_dataloader:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            pred = model(X)\n",
    "            predicted = (pred > 0.5).float()\n",
    "            predicted = predicted.argmax(dim=1)\n",
    "            y_pred.append(predicted)\n",
    "            y_correct.append(y)\n",
    "    \n",
    "    y_pred = torch.cat(y_pred, dim=0)\n",
    "    y_correct = torch.cat(y_correct, dim=0)\n",
    "\n",
    "    ## Métricas\n",
    "\n",
    "    f1score = MulticlassF1Score(num_classes=3)\n",
    "    precision_metric = MulticlassPrecision(num_classes=3)\n",
    "    recall_metric = MulticlassRecall(num_classes=3)\n",
    "    confusion_metric = MulticlassConfusionMatrix(num_classes=3)\n",
    "\n",
    "    f1score.update(y_correct, y_pred)\n",
    "    precision_metric.update(y_correct, y_pred)\n",
    "    recall_metric.update(y_correct, y_pred)\n",
    "    confusion_metric.update(y_correct, y_pred)\n",
    "\n",
    "    f1sc = f1score.compute()\n",
    "    precision = precision_metric.compute()\n",
    "    recall = recall_metric.compute()\n",
    "    confusion = confusion_metric.compute()\n",
    "\n",
    "    # Logar métricas\n",
    "    mlflow.log_metric(\"F1 Score\", f1sc)\n",
    "    mlflow.log_metric(\"Precision\", precision)\n",
    "    mlflow.log_metric(\"Recall\", recall)\n",
    "    mlflow.log_metric(\"Accuracy\", accuracy)\n",
    "\n",
    "    print('\\nMétricas logadas')\n",
    "\n",
    "\n",
    "    # Logando os pesos do modelo\n",
    "    #model_path = 'resnet-50-finetuned.pth'\n",
    "    #torch.save(model.state_dict(), model_path)  # Salva só os pesos\n",
    "    #mlflow.log_artifact(model_path)  # Loga o arquivo\n",
    "\n",
    "    # Logando o modelo\n",
    "\n",
    "    mlflow.pytorch.log_model(model, \"resnet-50-finetuned\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2adee87d",
   "metadata": {},
   "outputs": [],
   "source": [
    "metric = MulticlassF1Score(num_classes=3)\n",
    "\n",
    "metric.update(y_pred, y_correct)\n",
    "teste = metric.compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6b9a733f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.9467)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa35a73c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the model back for predictions as a generic Python Function model\n",
    "loaded_model = mlflow.pyfunc.load_model(model_info.model_uri)\n",
    "\n",
    "predictions = loaded_model.predict(X_test)\n",
    "\n",
    "iris_feature_names = datasets.load_iris().feature_names\n",
    "\n",
    "result = pd.DataFrame(X_test, columns=iris_feature_names)\n",
    "result[\"actual_class\"] = y_test\n",
    "result[\"predicted_class\"] = predictions\n",
    "\n",
    "result[:4]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "computer_vision",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
